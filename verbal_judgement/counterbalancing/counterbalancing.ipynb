{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth Duration: Stimulus Counterbalancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Class \n",
    "\n",
    "Creates a sequence such that each block is balanced in terms of depth and duration/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import random \n",
    "import copy \n",
    "import sqlite3\n",
    "import sys\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing group seq generation\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n",
      "Number of Unique Parents in Group:192\n"
     ]
    }
   ],
   "source": [
    "sequence_count = 0\n",
    "#encapsulates all data points for an object (i.e. image) --> all image characteristics are accessible\n",
    "class Observation:\n",
    "    def __init__(self, parent, subdir, depth):\n",
    "        self.parent = parent\n",
    "        self.subdir = subdir\n",
    "        self.depth = depth\n",
    "    def getParent(self):\n",
    "        return self.parent\n",
    "    def getSubdir(self):\n",
    "        return self.subdir\n",
    "    def getDepth(self):\n",
    "        return self.depth \n",
    "\n",
    "class Observation_bins: #4 bins organized by depth (1-2m, 2-3m, 3-4m, 4-5m)\n",
    "    def __init__(self):\n",
    "        self.bins = [[], [], [], []] #structure that holds organized bins \n",
    "        self.blocks = 4\n",
    "        self.stims_per_block = 48 \n",
    "        self.num_bins = 4\n",
    "        \n",
    "    def addObservation(self, obs): #puts image observations in the correct bin by depth \n",
    "        depth = obs.getDepth()\n",
    "        if depth >= 1 and depth < 2:\n",
    "            self.bins[0].append(obs)               \n",
    "        elif depth >= 2 and depth < 3:\n",
    "            self.bins[1].append(obs)\n",
    "        elif depth >= 3 and depth < 4:\n",
    "            self.bins[2].append(obs)\n",
    "        elif depth >= 4 and depth < 5:\n",
    "            self.bins[3].append(obs)\n",
    "        else:\n",
    "            sys.exit(\"Depth out of bounds\") #flag for if depth is less than 1 or greater than 5\n",
    "            \n",
    "    #randomly selects an image from a specified bin based on length of bin \n",
    "    def getObservation(self, bin_number): \n",
    "        if len(self.bins[bin_number]) == 0:\n",
    "            sys.exit(\"Bin is empty --> pseudo random solution failed, try again\")\n",
    "\n",
    "        random_number = int(random.random() * len(self.bins[bin_number]))\n",
    "#         print(\"Length of bin\" + str(bin_number)+\":\",len(self.bins[bin_number]) )\n",
    "#         print(\"Random number\", random_number)\n",
    "\n",
    "        return self.bins[bin_number][random_number]\n",
    "    \n",
    "    #removes all observations with the same parent (prevents preview effect)\n",
    "    def _deleteParent(self, sample_parent): #_ i.e. protocol; not called independently \n",
    "        deleted = 0\n",
    "        for i in range(len(self.bins)):  \n",
    "            for j in reversed(range (len(self.bins[i]))): #reversed because length of list shrinks as elements are deleted\n",
    "                parent = self.bins[i][j].getParent() \n",
    "                if parent == sample_parent:\n",
    "\n",
    "                    self.bins[i].pop(j)\n",
    "                    deleted += 1\n",
    "                    \n",
    "        #print(deleted, \"deleted\")\n",
    "        \n",
    "    \n",
    "    #takes in the image name and returns the depth of the target in that image by accessing the object instance associated with that image    \n",
    "    def findObservationDepth(self, stim):\n",
    "        for i in range(len(self.bins)):\n",
    "            for j in reversed(range (len(self.bins[i]))): #reversed because length of list shrinks as elements are deleted\n",
    "                img_subdir = self.bins[i][j].getSubdir()\n",
    "                if img_subdir == stim:\n",
    "                    img_depth = self.bins[i][j].getDepth()\n",
    "                    return img_depth\n",
    "                    \n",
    "                \n",
    "    \n",
    "    \n",
    "    #generates image sequence \n",
    "    def makeSequence(self): \n",
    "        # IMPORTANT: This is a member function. It is called on an instance of the class (clear because self is passed)\n",
    "        # So for example, when x.makeSequence() is called this function is operating within the instance of the class, which is x\n",
    "        # If I want to call other member functions, within this function, they should be called on self NOT x \n",
    "     \n",
    "        \n",
    "        #can add can option to create a folder with these images (self, destination aka name for sequence folder)\n",
    "        #if destination == \"\" then don't create sequence folder \n",
    "        # https://docs.python.org/2/library/copy.html; Need an immutable copy function, i.e. deepcopy \n",
    "        bins_backup = copy.deepcopy(self.bins)\n",
    "        s1_stim = []\n",
    "        for i in range(self.blocks): #creates 2d list based on num of blocks\n",
    "            s1_stim.append([])\n",
    "\n",
    "        check_dict = {}\n",
    "        img_duration = {} #key = image, value = assigned duration\n",
    "        #count variables verify that there are 64 images per duration total \n",
    "        count250 = 0\n",
    "        count500 = 0\n",
    "        count750 = 0\n",
    "        count1000 = 0\n",
    "        for block in range(self.blocks): #4 blocks in the experiment\n",
    "            for stim_num in range(int(self.stims_per_block/self.num_bins)): # 64 images in each block\n",
    "                for bin_num in range(self.num_bins):\n",
    "                    #randomly sampled observation \n",
    "                    sample_obs = self.getObservation(bin_num)\n",
    "                    sample_depth = sample_obs.getDepth()\n",
    "                    sample_parent = sample_obs.getParent()\n",
    "                    #call a function to delete that parent from the list of images to prevent duplicates \n",
    "                    self._deleteParent(sample_parent)\n",
    "                    sample_image = sample_obs.getSubdir()\n",
    "                    #adds image filename to sequence list \n",
    "                    s1_stim[block].append(sample_image)\n",
    "                    #add image names to dictionary to ensure no duplicate images are added \n",
    "                    if sample_image not in check_dict:\n",
    "                        check_dict[sample_image] = 1\n",
    "                    else:\n",
    "                        sys.exit(\"Duplicate found: \" + sample_image)\n",
    "                        \n",
    "                    # Duration sequence: 16 images per bin per block per duration \n",
    "                    # Ex. in block 1 there are 16 images from bin1 @ 250 ms \n",
    "                    # Ideally should not be hard coded ... \n",
    "                    \n",
    "                    #first 16 images (stim_num 0-3)\n",
    "                    if stim_num <= 3: \n",
    "                        img_duration[sample_image] = 250\n",
    "                        count250 += 1\n",
    "                    #second 16 images (stim_num 4-7)\n",
    "                    elif stim_num > 3 and stim_num <= 7:\n",
    "                        img_duration[sample_image] = 500\n",
    "                        count500 += 1\n",
    "                    #third 16 images (stim_num 8-11)\n",
    "                    elif stim_num > 7 and stim_num <= 11:\n",
    "                        img_duration[sample_image] = 750\n",
    "                        count750 +=1\n",
    "                    #last 16 images (stim_num 12-15)\n",
    "                    elif stim_num > 11 and stim_num <= 15:\n",
    "                        img_duration[sample_image] = 1000\n",
    "                        count1000 += 1\n",
    "                        \n",
    "\n",
    "        #randomly shuffle the elements of each block \n",
    "        for block in s1_stim:\n",
    "            random.shuffle(block)\n",
    "            \n",
    "        #generate duration sequence based on the SHUFFLED order of selected images \n",
    "        s1_duration_seq = []\n",
    "        for i in range(self.blocks): #creates 2d list based on num of blocks\n",
    "            s1_duration_seq.append([])\n",
    "            \n",
    "        for block in range(self.blocks):\n",
    "            for img in s1_stim[block]:\n",
    "                duration = img_duration[img]\n",
    "                s1_duration_seq[block].append(duration)\n",
    "                \n",
    "        self.bins = bins_backup #resets the main bins list back to the original for the next sequence \n",
    "        \n",
    "                \n",
    "        # Database structure \n",
    "\n",
    "        # sequence_A = [(sequence_A, img1, bin1-2, 500), (sequence_A, img2, bin4-5, 250)...]\n",
    "        # TUPLE = (sequence name, img name, duration, order of presentation = 1 if the first image, depth )\n",
    "        entry = []\n",
    "        for block in s1_stim:\n",
    "            for stim in block:\n",
    "                 ## finding the number of presentation of the image in the overall sequence ##\n",
    "                block_index = s1_stim.index(block)\n",
    "                index_in_block = block.index(stim) + 1 #plus one so that indices start at 1 not zero \n",
    "                overall_index = len(block)*block_index + index_in_block\n",
    "                \n",
    "                #indexes to find corresponding duration for the image \n",
    "                duration = s1_duration_seq[block_index][index_in_block-1]    \n",
    "                \n",
    "                depth = self.findObservationDepth(stim)\n",
    "                img_list = ['placeholder_sequence_name', stim, duration, overall_index, depth]\n",
    "                #convert into tuple later once sequence name is known\n",
    "                entry.append(img_list)\n",
    "                \n",
    "        \n",
    "        # Removes images that were sampled in s1_stim (current sequence)\n",
    "        count = 0\n",
    "        for i in range(len(self.bins)):\n",
    "            for j in reversed(range (len(self.bins[i]))): #reversed because length of list shrinks as elements are deleted\n",
    "                subdir = self.bins[i][j].getSubdir()                    \n",
    "                for block in s1_stim:\n",
    "                    if subdir in block:\n",
    "                        self.bins[i].pop(j)\n",
    "                        count += 1\n",
    "                        \n",
    "        #print([count250, count500, count750, count1000])\n",
    "        \n",
    "        return s1_stim, s1_duration_seq, entry\n",
    "    \n",
    "               \n",
    "def getTargetInfo(directory):\n",
    "    \"\"\"\n",
    "    Indexes into the json file of each image and recursively extracts image characteristics\n",
    "    All object (target image) instances are added to obs_bins (main list of all images)\n",
    "    Args: \n",
    "        directory = path to cleaned stimuli folder\n",
    "    Returns:\n",
    "        obs_bins = instance of Observation_bins class that has depth_ob (instance) for every target image\n",
    "    \"\"\"\n",
    "#     print(\"running\")\n",
    "    \n",
    "    obs_list = [] #[parent, filepath, depth] for all of the images \n",
    "    obs_bins = Observation_bins() #instance of the class \n",
    "    for subdir, dirs, files in os.walk(directory): #recursively goes through all the folders within ltq\n",
    "        for file in files:\n",
    "            filepath = subdir + os.sep + file\n",
    "            if \".ipynb_checkpoints\" not in str(subdir):\n",
    "                if filepath.endswith(\".json\"):\n",
    "                    output_json = json.load(open(filepath)) #loads each data.json file from ltq\n",
    "                    objects = output_json['objects'] \n",
    "                    for obj in objects:\n",
    "                        cp = obj[\"crossing_point\"]\n",
    "                        cp = cp[0] #indexes to the dict\n",
    "                        depth = cp['depth']\n",
    "                        \n",
    "                        elem_split = subdir.split(\"/\")\n",
    "                        img = elem_split[-1] #image folder is the last element of the path\n",
    "                        img_split = img.split(\"_\")\n",
    "                        parent = img_split[0]\n",
    "                        depth_ob = Observation(parent, subdir, depth) #creating an instance\n",
    "                        obs_bins.addObservation(depth_ob) #adding one object to another (an observation to the bins list)\n",
    "    return obs_bins        \n",
    "        \n",
    "# obs_bins = getTargetInfo() #called on directory where images are stored \n",
    "\n",
    "obs_bins = getTargetInfo(\"/Users/prachi/Documents/depth_duration/mar3_depthDuration_stimuli/targetImages_kinect2data_subset\")\n",
    "\n",
    "#### MAIN PROGRAM BEGINS HERE #### \n",
    "  \n",
    "def generateFourSequences(obs_bins, mother_group):\n",
    "    \"\"\"\n",
    "    After a sequence is made, those target images (not parent) are removed from the master list \n",
    "    Once 4 sequences can be made in this way because of stimuli constraints\n",
    "    NOTE: sometimes 4 sequences might not work because of the variability of random sampling - in that case exception is thrown\n",
    "    \"\"\"\n",
    "    #list of the names of the sequences \n",
    "    #Mother group is used now since sequences are made in groups of 4\n",
    "    #seq_names = [mother_group+\"1\", mother_group+\"2\", mother_group+\"3\", mother_group+\"4\"]\n",
    "    seq_names = [mother_group+\"1\"]\n",
    "\n",
    "    lst_seq = []\n",
    "    for i in range(len(seq_names)): #generate 4 sequences, add entry to list of sequences\n",
    "        output = obs_bins.makeSequence()\n",
    "        entry = output[2]\n",
    "        lst_seq.append(entry)\n",
    "\n",
    "    entry_list = [] #list of image tuples for all trials in all sequences\n",
    "    for seq in lst_seq:\n",
    "        for item in seq:\n",
    "            index = lst_seq.index(seq)\n",
    "            item[0] = \"sequence_\" + seq_names[index] #replaces \"placeholder sequence name\" with actual name \n",
    "            item = tuple(item) #converts list to tuple so it can be added to the database \n",
    "            entry_list.append(item)\n",
    "                        \n",
    "            \n",
    "    return entry_list\n",
    "\n",
    "\n",
    "class Group:\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences #listofGroupSequences --> [(), (), ...] --> tuples for the trials for all four sequences of that group\n",
    "    \n",
    "    def getNumParents(self):\n",
    "        \"\"\"\n",
    "        Member function of Group class \n",
    "        Returns number of unique parents in the group \n",
    "        \"\"\"\n",
    "        \n",
    "        lst_group_parents = []\n",
    "        for trial in self.sequences:\n",
    "            folder_path = trial[1] #path to parent folder\n",
    "            fp_split = folder_path.split(\"/\")\n",
    "            folder = fp_split[-1]\n",
    "            folder_split = folder.split(\"_\")\n",
    "            parent = folder_split[0] #isolated parent image name\n",
    "            lst_group_parents.append(parent)\n",
    "                \n",
    "#         print(\"Parent List length: \", len(lst_group_parents)) #should be 256 * 4 = 1024\n",
    "        \n",
    "        set_groupParents = set(lst_group_parents) #convert to set so duplicates are removed\n",
    "#         print(\"Parent Set length: \", len(set_groupParents)) \n",
    "\n",
    "        return len(set_groupParents) #total number of unique parents in the group\n",
    "    \n",
    "    def returnGroup(self):\n",
    "        \"\"\"\n",
    "        Member function of Group class \n",
    "        Returns the group (4 sequences) in its original form \n",
    "        \"\"\"\n",
    "        return self.sequences \n",
    "        \n",
    "\n",
    "def findBestGroup(stimuli_path):\n",
    "    \"\"\"\n",
    "    Generates groups of 4 sequences \n",
    "    Returns the group that has the maximum amount of unique parent images \n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Testing group seq generation\")\n",
    "    \n",
    "    complete_entry = []\n",
    "        \n",
    "    group_names = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\" ,\"M\", \n",
    "                   \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]    \n",
    "    \n",
    "    \n",
    "    for name in group_names:\n",
    "        obs_bins = getTargetInfo(stimuli_path) #resets obs_bins after 4 sequences are made \n",
    "        listofGroupSequences = generateFourSequences(obs_bins, name) #1D list of tuples \n",
    "        group_entry = Group(listofGroupSequences) #Group is a class \n",
    "        # group_entry is an instance of the class \n",
    "        complete_entry.append(group_entry) #list of group objects \n",
    "    \n",
    "    #https://www.agnosticdev.com/content/how-sort-objects-custom-property-python\n",
    "    #sort complete_entry based on number of parents in each group \n",
    "    #getNumParents() is a member function\n",
    "    # lambda specifies that I am running a function on each element\n",
    "    # it loops through all elements (groups) of complete_entry (element = x)\n",
    "    # reverse = True --> maximum to minimum \n",
    "    \n",
    "    complete_entry.sort(key=lambda x: x.getNumParents(), reverse=True)\n",
    "    \n",
    "    for group in complete_entry:\n",
    "        print(\"Number of Unique Parents in Group:\" + str(group.getNumParents()))\n",
    "        \n",
    "    max_group = complete_entry[0].returnGroup() #0 because complete_entry is ordered max --> min\n",
    "        \n",
    "    return max_group \n",
    "\n",
    "def foo(stimulus_path):\n",
    "    \"\"\"\n",
    "    Restarts findBestGroup after exception (random sequence solution fails)\n",
    "    Args:\n",
    "        stimulus_path = SUN-RGBD cleaned stimuli folder \n",
    "    Returns:\n",
    "        Group of sequences that has the maximum number of parent images\n",
    "        - list of trial tuples for four sequences (ex. a1, a2, a3, a4)\n",
    "        - this list should be inputted to database \n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            bestGroup = findBestGroup(stimulus_path)\n",
    "            return bestGroup\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "path = \"/Users/prachi/Documents/depth_duration/mar3_depthDuration_stimuli/targetImages_kinect2data_subset\"\n",
    "Group_max_parents = foo(path)\n",
    "# print(Group_max_parents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of cleaned target stimuli (Used to select a group of balanced 192 images)\n",
    "\n",
    "Criterion\n",
    "- good depth tagging \n",
    "- minimal camera rotation \n",
    "- target placement is not ambiguous \n",
    "- no people in the scene \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1405\n"
     ]
    }
   ],
   "source": [
    "cleaned_target_stim = []\n",
    "\n",
    "for folder in os.listdir(path):\n",
    "    if folder != '.DS_Store':\n",
    "        cleaned_target_stim.append(folder)\n",
    "    \n",
    "print(len(cleaned_target_stim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optmized Sequence Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of images: even spread of depth\n",
    "\n",
    "[stimuli ordered from 1m to 5m] = 192 total images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "depth_ob_output = Group_max_parents\n",
    "\n",
    "stimuli = [[trial[1], trial[4]] for trial in depth_ob_output]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Folders include in the depth_ob sequence\n",
    "\n",
    "Select 4 images for the practice trials (3) and example image that are NOT in the list below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_num = [trial[0].split('/')[-1].split('_')[0] for trial in stimuli]\n",
    "\n",
    "folders_num.sort() \n",
    "# folders_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create folder with target image folders selected by depth_ob code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil \n",
    "\n",
    "dest = '/Users/prachi/Documents/depth_duration/mar3_depthDuration_stimuli/final_stimuli'\n",
    "\n",
    "for stim in stimuli:\n",
    "    folderpath = stim[0]\n",
    "    dest_folder = dest  + '/' + stim[0].split('/')[-1]\n",
    "    destination = shutil.copytree(folderpath, dest_folder)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  192\n"
     ]
    }
   ],
   "source": [
    "# confirm that there are 192 images \n",
    "\n",
    "count = 0\n",
    "for folder in os.listdir(dest):\n",
    "    count += 1\n",
    "print(\"Number of images: \", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort trials by depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort_Depth(sub_li):\n",
    "    \"\"\"\n",
    "    Sort the tuples using the second element\n",
    "    Inplace way to sort using sort()\n",
    "    \"\"\"\n",
    "    # reverse = None (Sorts in Ascending order)\n",
    "    # key is set to sort using second element of\n",
    "    # sublist lambda has been used\n",
    "    sub_li.sort(key = lambda x: x[1])\n",
    "    return sub_li\n",
    "\n",
    "# conditions = random permutations list flattened so that each elem has a numerical assignment which will evenly distribute the durations\n",
    "# PERMUTATIONS should be 0, 1, 2, 3\n",
    "# then put them into blocks strategically by sampling one at a time and adding to array\n",
    "sorted_stimuli_depth = Sort_Depth(stimuli)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/prachi/Documents/depth_duration/mar3_depthDuration_stimuli/targetImages_kinect2data_subset/002272_2014-06-28_18-53-56_260595134347_rgbf000067-resize_2',\n",
       " 1.138]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_stimuli_depth[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign duration condition in block structure to create sequence \n",
    "\n",
    "48 images in each block --> 12 images at each duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_permutations():\n",
    "    permutations = list(itertools.permutations([250, 500, 750, 1000])) * 2\n",
    "    random.shuffle(permutations)\n",
    "\n",
    "    # list of duration conditions \n",
    "    permutations = [item for tup in permutations for item in tup] \n",
    "    \n",
    "    return permutations\n",
    "\n",
    "def Sort_Duration(sub_li):\n",
    "    \"\"\"\n",
    "    Sort the tuples using the third element\n",
    "    Inplace way to sort using sort()\n",
    "    \"\"\"\n",
    "    # reverse = None (Sorts in Ascending order)\n",
    "    # key is set to sort using second element of\n",
    "    # sublist lambda has been used\n",
    "    sub_li.sort(key = lambda x: x[2])\n",
    "    return sub_li\n",
    "\n",
    "def sequence(sorted_stimuli):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Stimuli sorted by DEPTH \n",
    "    Returns:\n",
    "        Balanced sequence by depth and duration\n",
    "    \"\"\"\n",
    "    permutations = get_permutations()\n",
    "    \n",
    "    stim_depth_dur = copy.deepcopy(sorted_stimuli_depth)\n",
    "    for i in range(len(stim_depth_dur)):\n",
    "        stim_depth_dur[i].append(permutations[i])\n",
    "\n",
    "    sorted_stim_depth_dur = Sort_Duration(stim_depth_dur)\n",
    "    \n",
    "    test_seq = [[], [], [], []]\n",
    "    test = copy.deepcopy(sorted_stim_depth_dur)\n",
    "    \n",
    "    for i in range(4):\n",
    "        # i = index for duration\n",
    "        for j in range(4):\n",
    "            # j = index for depth bin\n",
    "            # trials at duration i, in depth bin j --> e.g. all trials at 250 ms with depths between 1-2m\n",
    "            temp = copy.deepcopy(test[48*i:48*(i+1)][12*j:12*(j+1)])\n",
    "            random.shuffle(temp)\n",
    "            # split list into 4 for each block\n",
    "            # 3 images for for each depth bin for each duration \n",
    "            temp = [temp[0:3], temp[3:3*2], temp[3*2:3*3], temp[3*3:3*4]]   \n",
    "            random.shuffle(temp)\n",
    "            # add the split lists to the sequence blocks \n",
    "            for k in range(4):\n",
    "                for elem in temp[k]:\n",
    "                    test_seq[k].append(elem)\n",
    "\n",
    "    # randomly shuffle trials in each block\n",
    "\n",
    "    for block in test_seq:\n",
    "        random.shuffle(block)\n",
    "    \n",
    "    return test_seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create 48 sequences using different duration permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(sorted_stimuli, num):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sorted_stimuli = Stimuli sorted by DEPTH \n",
    "        num = number of sequences to be generated\n",
    "    Returns:\n",
    "        list of sequences \n",
    "    \"\"\"\n",
    "    list_sequences = {}\n",
    "    label = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "              'ab', 'ac', 'ad', 'ae', 'af', 'ag', 'ah', 'ai', 'aj', 'ak', 'al', 'am', 'an', 'ao', 'ap', 'aq', 'ar', 'as', 'at', 'au', 'av', 'aw', 'ax', 'ay', 'az']\n",
    "    for i in range(num):\n",
    "        # sequence seperated by block\n",
    "        seq = sequence(sorted_stimuli)\n",
    "        # flattens sequence \n",
    "        seq = [item for sublist in seq for item in sublist]\n",
    "        list_sequences[label[i]] = seq\n",
    "    \n",
    "    return list_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_48 = main(sorted_stimuli_depth, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequences_48.keys()\n",
    "\n",
    "len(sequences_48['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_jsons(list_of_sequences, destination):\n",
    "\n",
    "    sequence_dictionaries = []\n",
    "    for key in list_of_sequences.keys():\n",
    "        seq = [] \n",
    "        sequence_name = key\n",
    "        num = 0\n",
    "        for trial in list_of_sequences[key]:\n",
    "            dict_trial = {}\n",
    "            dict_trial[\"sequence\"] = sequence_name\n",
    "            dict_trial[\"image\"] = trial[0]\n",
    "            dict_trial[\"duration\"] = trial[2]\n",
    "            dict_trial[\"num\"] = num\n",
    "            dict_trial[\"depth\"] = trial[1]\n",
    "            local_imgpath = trial[0]\n",
    "            img_num = local_imgpath.split(\"/\")[-1]\n",
    "            # this has to be the path on the server\n",
    "            ogimg_path = \"depth_duration_stimuli/\" + img_num + '/' + img_num +'-original.jpg'\n",
    "            targetimg = \"depth_duration_stimuli/\" + img_num + '/' + img_num + '-target.png'\n",
    "            dict_trial[\"image_path\"] = ogimg_path\n",
    "            dict_trial[\"image_path_target\"] = targetimg\n",
    "            dict_trial[\"mask_path\"] = \"masks/mask_\" + str(num) + \".jpg\"\n",
    "            dict_trial[\"fixation_path\"] = \"fixation.jpg\"\n",
    "\n",
    "            seq.append(dict_trial)\n",
    "            num += 1\n",
    "\n",
    "        sequence_dictionaries.append(seq)\n",
    "    \n",
    "    for sequence in sequence_dictionaries:\n",
    "        name = sequence[0][\"sequence\"]\n",
    "        path = destination + '/' + name + '.json'\n",
    "        #creates json file for the sequence \n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(sequence , f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a json file for each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons_destination = '/Users/prachi/Documents/depth_duration/SUN-RGBD_stimuli_prep/V2_sequences'\n",
    "\n",
    "create_sequence_jsons(sequences_48, jsons_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Duration Rotated Sequences \n",
    "\n",
    "- goal is for each image to be seen at each duration across all participants \n",
    "- duration effects for individual target images can then be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "def load_master_sequence(jsonpath):\n",
    "    return json.load(open(jsonpath))\n",
    "\n",
    "def rotate_sequence(previous_seq):\n",
    "    \"\"\"\n",
    "    Rotates each trial's duration assignment based on previous sequence \n",
    "    250 --> 500\n",
    "    500 --> 750\n",
    "    750 --> 1000\n",
    "    1000 --> 250\n",
    "    \"\"\"\n",
    "    rotated = previous_seq\n",
    "    for i in range(len(previous_seq)):\n",
    "        duration = previous_seq[i]['duration']\n",
    "        if duration == 1000:\n",
    "            new_duration = 250\n",
    "        else:\n",
    "            new_duration = duration + 250\n",
    "        rotated[i]['duration'] = new_duration\n",
    "        \n",
    "    return rotated\n",
    "\n",
    "def create_duration_rotations(jsonpath, exit, name):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        jsonpath = path to master json created through sequence pipeline\n",
    "        exit = destination path for new jsons \n",
    "        name = i.e. V1 \n",
    "    \n",
    "    Creates sequences rotated by duration so that all images in the master sequence are seen at each duration\n",
    "    (across participants)\n",
    "        \n",
    "    \"\"\"\n",
    "    master = load_master_sequence(jsonpath)\n",
    "    \n",
    "#     r0 = master \n",
    "#     r0_path = exit + '/' + name + '_0.json'\n",
    "#     #creates json file for the sequence \n",
    "#     with open(r0_path, 'w') as f:\n",
    "#         json.dump(r0 , f)\n",
    "        \n",
    "#     r1 = rotate_sequence(r0)\n",
    "    r1 = rotate_sequence(master)\n",
    "    r1_path = exit + '/' + name + '_1.json'\n",
    "    #creates json file for the sequence \n",
    "    with open(r1_path, 'w') as f:\n",
    "        json.dump(r1 , f)\n",
    "        \n",
    "    r2 = rotate_sequence(r1)\n",
    "    r2_path = exit + '/' + name + '_2.json'\n",
    "    #creates json file for the sequence \n",
    "    with open(r2_path, 'w') as f:\n",
    "        json.dump(r2 , f)\n",
    "        \n",
    "    r3 = rotate_sequence(r2)\n",
    "    r3_path = exit + '/' + name + '_3.json'\n",
    "    #creates json file for the sequence \n",
    "    with open(r3_path, 'w') as f:\n",
    "        json.dump(r3 , f)    \n",
    "\n",
    "        \n",
    "def main_seq_rotations(json_folderpath, exit):\n",
    "    \"\"\"\n",
    "    Create rotated sequence for each sequence in the folder\n",
    "    \"\"\"\n",
    "    for file in os.listdir(json_folderpath):\n",
    "        name = file.split(\".\")[0]\n",
    "        jsonpath = json_folderpath + \"/\" + file\n",
    "        try:\n",
    "            create_duration_rotations(jsonpath, exit, name)\n",
    "        except:\n",
    "            print(\"Failed to create json rotations for: \", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to create json rotations for:  .DS_Store\n",
      "Failed to create json rotations for:  .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "jsons_location = '/Users/prachi/Documents/depth_duration/SUN-RGBD_stimuli_prep/V2_sequences'\n",
    "jsons_destination = '/Users/prachi/Documents/depth_duration/SUN-RGBD_stimuli_prep/V2_sequences'\n",
    "\n",
    "main_seq_rotations(jsons_location, jsons_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
